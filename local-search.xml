<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Diffusion Models + NLP 杂谈</title>
    <link href="/2023/11/06/DiffusionNLP/"/>
    <url>/2023/11/06/DiffusionNLP/</url>
    
    <content type="html"><![CDATA[<h1 id="exploring-the-future-of-diffusion-models-in-nlp">Exploring the Future of Diffusion Models in NLP</h1><h2 id="引言">引言</h2><p>这篇博客用于记录9月-10月的看论文心得，关于Diffusion Model和NLP结合的探索。（当然，11月的我现在觉得几乎完全一种蹭热度的科研废物，毫无意义）不过，还是可以简单探索一下。</p><p>所以，本篇博客主要focus在以下四个方面：</p><ul><li>回顾一些主流的Diffusion Model 和 NLP结合方法</li><li>介绍更大规模的 diffusion 和 nlp 结合的模型，即参数更多。</li><li>介绍 diffusion 和 nlp 结合的小众应用方式（文本生成以外）</li><li>Diffusion Model 结合novel的文本生成方法</li></ul><h3 id="review">1. Review</h3><figure><img src="/img/DiffusionNLP/review_skills.png" alt="review" /><figcaption aria-hidden="true">review</figcaption></figure><p>这张图来自今年5月份的survey-<a href="https://arxiv.org/abs/2305.14671">A Survey of Diffusion Models in Natural Language Processing</a>。</p><p>比如，能提高文本生成性能的方法有self-conditioning等。用在continuous diffusion中的则是图片右半边部份的策略，比如anchor loss也在diffusion-LM中使用了。</p><p>除此之外，在检索论文时，也有看过一篇diffusion+NLP的paper，它在别人的模型上加了self-conditioning的方法，就说自己性能提高了比别人好。我个人认为是比较滑水的做法。</p><h3 id="scale-up-the-diffusion-models-in-nlp">2. Scale up the diffusion models in NLP</h3><p>第一篇 paper ：<a href="https://aclanthology.org/2023.acl-long.647.pdf">SSD-LM</a>，SSD-LM是2022年10月挂在Arxiv的paper，中了ACL2023。</p><h4 id="相关的背景知识">相关的背景知识</h4><ol type="1"><li>Diffusion Model，太复杂了，本篇不做详细介绍。</li><li>自回归语言模型。对于一个 <span class="math inline">\(w_0\)</span>，<span class="math inline">\(w_1\)</span>，到 <span class="math inline">\(w_{l-1}\)</span> 的长度为 <span class="math inline">\(L\)</span> 的 sequence ，在自回归语言模型中可以表示为公式4，即当前token是由前面所有token预测得到。</li></ol><figure><img src="/img/DiffusionNLP/formula1.png" alt="formula1" /><figcaption aria-hidden="true">formula1</figcaption></figure><p>这个模型的 <mark>Decoding</mark> 的过程同理，是通过 left-to-right 的迭代生成方式。这类自回归模型也有缺点，比如说容易导致句子重复，以及没法自然的融合sequence-level的可控生成。</p><p>因此在这篇文章中，作者通过提出了一个半自回归的语言模型，它通过结合 diffusion models 来解决 autoregressive model 的一些问题。</p><h3 id="ssd-lm">2-1 SSD-LM</h3><h4 id="method">Method</h4><p>在SSD-LM中，diffusion model使用高斯噪声来解码长度为 <span class="math inline">\(b\)</span> 个tokens的一个块，且以 <span class="math inline">\(w^{&lt;c}\)</span> 的 tokens 组成序列作为条件。</p><h4 id="training">Training</h4><p>如图所示，<mark>前向扩散过程</mark>是在某个 token <span class="math inline">\(w\)</span> 上进行，而不是在全部tokens 上面进行。</p><figure><img src="/img/DiffusionNLP/Method1.png" alt="method1" /><figcaption aria-hidden="true">method1</figcaption></figure><p>在training的过程中，首先进行mapping，把每个token <span class="math inline">\(w\)</span> 对应一个维度跟词表大小一样维度的one-hot向量，表示每个单词的对率。</p><p>然后使用连续的高斯噪声进行前向扩散过程。loss函数中，也是用了似然来替代l2 distance。</p><figure><img src="/img/DiffusionNLP/formula3.png" alt="formula3" /><figcaption aria-hidden="true">formula3</figcaption></figure><figure><img src="/img/DiffusionNLP/formula4.png" alt="formula4" /><figcaption aria-hidden="true">formula4</figcaption></figure><h4 id="decoding">Decoding</h4><p>在解码过程中，模型使用噪声对率作为输入，并通过预测对率来估计原始token的分布。同时，为了进行逆向diffusion过程，设计一个logits-projection的方式，让预测数据表征接近原始数据表征（almost-one-hot）。</p><p>decoding的过程从纯噪声开始采样，并使用第t步计算t-1的值，与一般的reverse diffuson过程相似。</p><figure><img src="/img/DiffusionNLP/formula5.png" alt="formula5" /><figcaption aria-hidden="true">formula5</figcaption></figure><p>为了生成下一个的block，把当前block连接到之前的blocks以创建一个长度为 c+B 的新上下文，并再次遵循上述反向扩散过程。 重复此过程，直到达到所需的最大长度。</p><figure><img src="/img/DiffusionNLP/Method2.png" alt="Method2" /><figcaption aria-hidden="true">Method2</figcaption></figure><p>最后是，高度模块化可控的过程，增加了目标方向y，并在梯度更新过程中，让模型靠近classifer的指导。</p><figure><img src="/img/DiffusionNLP/formula6.png" alt="formula6" /><figcaption aria-hidden="true">formula6</figcaption></figure><p>得到的结果如下图所示，可以看出来在一些评价指标上，优于参数量更大的GPT2模型。在可控生成方向，也表现出了较好的可控性。</p><figure><img src="/img/DiffusionNLP/results1.png" alt="result1" /><figcaption aria-hidden="true">result1</figcaption></figure><p>这篇文章在结合了autoregressive language model和non-autoregressive diffusion model的特点。SSD-LM的<mark>局限性</mark>在于采样效率、解码速度和固定的解码block size。</p><h3 id="ssd-2">2-2 SSD-2</h3><p>因为我最近主要都是在看diffusion nlp结合的文章，我发现<mark>大多数文章，都几乎没有与大语言模型进行对比</mark>，直到看到了这篇文章，<a href="https://arxiv.org/abs/2305.14771">SSD-2</a>，这篇文章是今年5月发表的，在GPT-4提出来之后的。</p><p>也是同一个作者，作者的工作是在 MetaAI 工作过程完成的，<mark>SSD-2</mark> 是base 在SSD-LM模型上开展的。不同之处在于SSD-LM的模型参数只有0.4B，但是SSD-2的模型参数扩大到了<mark>13B</mark>，虽然远远达不到LLM的参数规模，但是在现有的Diffusion和NLP结合的模型中最大。</p><p>相比于SSD-LM模型：</p><ul><li>0.4B 拓展到 13B 的参数规模。</li><li>加入了一些（我在review中提到的）<strong>skills</strong>，比如说self-conditioning。这些skills都能在不同方面提升模型的性能。</li><li>使用了finetuning的方法，对instruction相关的dataset进行了finetune。作者得出的结论是，对比与Autoregressive模型的baseline，SSD-2的finetune模型效率更好，因为能够更好地利用双向的本文信息。</li></ul><figure><img src="/img/DiffusionNLP/results2.png" alt="results2" /><figcaption aria-hidden="true">results2</figcaption></figure><p>这张图是作者在训练时尝试了三种不同的参数规模，且从图中可看出来，13B的模型loss值还比较高，模型受限于计算资源没有完成收敛。而后面的实验结果，也全是在模型未完全收敛的情况下进行对比的。</p><h4 id="spotlight1-chat-style-instruction-finetuning">Spotlight1: Chat-style instruction finetuning</h4><p>这篇文章相对比与之前的diffusion nlp结合的文章，我觉得他的亮点首先是chat-style 的instruction finetuning的方式。很好的结合了当前的热点，也没有回避大语言模型在当前NLP领域的引领地位。同时尝试在diffusionNLP模型中进行了对话的形式。</p><p>作者使用dolly dataset进行finetune，他也是alpaca和vicuna模型用来训练的数据集。对于ssd-2 finetune性能评价，使用了GPT-4模型。从实验结果表中可以看出，SSD-2模型在同规模自回归模型中具有竞争力。</p><figure><img src="/img/DiffusionNLP/results3.png" alt="results3" /><figcaption aria-hidden="true">results3</figcaption></figure><p>且作者指出，使用的对比模型相比于SSD-2，使用了更多数据集进行训练，但SSD-2仍然在胜过某些模型。因此作者认为，如果ssd-2使用相同规模的模型参数进行训练，可能能够表现的更好。</p><h4 id="spotlight2-inference-time-collaboration">Spotlight2: Inference-time collaboration</h4><p>第二个亮点 则考虑了用户交互的过程。现在的大语言模型是比较通用的，但用户会更偏向于使用结合自身情况的模型，而SSD-2则考虑了这种情况。</p><p>首先是问题的set up：</p><ul><li>Purpose: to customize the system with their own data.</li><li>Setup:<ul><li><mark>A core model <span class="math inline">\(θ_{core}\)</span></mark> : good at general-domain instruction following.</li><li><mark>A user model <span class="math inline">\(θ_{user}\)</span> </mark>: computationally friendly for a typical user to run on their personal device or a cloud device to their control.</li><li><mark>A prompting instruction <span class="math inline">\(w_{inst}\)</span><mark/> both the models have access to.</li><li><mark>A expert data <span class="math inline">\(D_user\)</span></mark> only the user model and not the core model has access to.</li></ul></li></ul><p>Core model擅长于通用领域的指令回答。User model 对于用户更加友好，适用于个人设备或者云设备。Prompting instruction 和 expert data， 即用户个人数据</p><figure><img src="/img/DiffusionNLP/Method3.png" alt="method3" /><figcaption aria-hidden="true">method3</figcaption></figure><p>During inference:</p><ul><li><span class="math inline">\(θ_{core}\)</span> only takes in the prompt <span class="math inline">\(w_{inst}\)</span>, <span class="math inline">\(f_{θ_{core}} (w_{inst})\)</span>.</li><li>the user model takes in both the user expert data and the instruction as input <span class="math inline">\(f_{θ_{user}} (D_{user}, w_{inst})\)</span>.</li></ul><p>在inference 阶段Core model 使用prompt作为输入，user model把expert data和prompt同时作为输入。不同于autoregressive models，diffusion based models可以使用双向上下文迭代优化生成的令牌块。</p><p>结果也是使用GPT3.5进行评分。可以看出，提出的SSD-2模型在collaboration协作的setting下面，有一定的效果。</p><figure><img src="/img/DiffusionNLP/results4.png" alt="results4" /><figcaption aria-hidden="true">results4</figcaption></figure><h3 id="different-applications-of-diffusion-models-in-nlp">3. Different applications of diffusion models in NLP</h3><p>第三个我想提及的diffusion nlp发展方向是，除了文本生成外的应用方向。 <a href="https://aclanthology.org/2023.findings-acl.478.pdf">DiffuDetox</a>是ACL2023的文章，把diffusion和nlp结合的模型应用到了文本去毒里。可以理解为去除一些粗俗不适的文本，如table1所示。</p><figure><img src="/img/DiffusionNLP/results5.png" alt="results5" /><figcaption aria-hidden="true">results5</figcaption></figure><p>而diffudetox使用了混合的有条件和无条件的diffusion model。其中条件diffusion model把toxic text作为条件输入，而无条件的模型的训练是为了还原输入的文本内容。</p><p>DiffuDetox:</p><ul><li>a mixed conditional and unconditional diffusion model for text detoxification.</li><li>The conditional model takes toxic text as the condition and reduces its toxicity, yielding a diverse set of detoxified sentences.</li><li>The unconditional model is trained to recover the input text, which allows the introduction of additional fluent text for training and thus ensures text fluency.</li></ul><p>框架如图所示:</p><figure><img src="/img/DiffusionNLP/Method4.png" alt="method4" /><figcaption aria-hidden="true">method4</figcaption></figure><p>然后是实验结果，也能看出这种方法会大部份baseline好，甚至在一些指标上达到了sota性能。</p><figure><img src="/img/DiffusionNLP/results6.png" alt="results6" /><figcaption aria-hidden="true">results6</figcaption></figure><h3 id="novel-text-generation-ways">4. Novel text generation ways</h3><p>最后一个可能可以进行下去的方向是提出一些新颖的与diffusion model结合的文本生成方式。去年我在ICLR2023上看到了一种语言模型的生成方式: <a href="https://openreview.net/forum?id=FkSp8VW8RjH">Language Modelling with Pixels</a>，是使用像素（图像）的方式对文本进行建模，再生成。其框架如下所示。使用这种方法的好处是，对于拼写错误攻击和语言代码切换更健壮。</p><figure><img src="/img/DiffusionNLP/Method5.png" alt="method5" /><figcaption aria-hidden="true">method5</figcaption></figure><p>然后我在进行diffusion model和nlp检索时，也看到了引用了这篇文章的一个paper: <a href="https://arxiv.org/abs/2304.12519">GlyphDiffusion: Text Generation Is Also Image Generation</a>，是今年4月份挂在arxiv上的文章，它的建模方式跟ICLR那篇文章是一样。</p><figure><img src="/img/DiffusionNLP/Method6.png" alt="method6" /><figcaption aria-hidden="true">method6</figcaption></figure><p>实验结果如下：</p><figure><img src="/img/DiffusionNLP/results7.png" alt="results7" /><figcaption aria-hidden="true">results7</figcaption></figure><p>同时，这篇文章比起对文本diffusion有一个好处是，可以直接把在图像diffusion领域发展的先进知识引入进来。结果如下所示，作者认为使用这种建模方法能够产生更diverse的文本，同时减少重复和错误拼写。</p><h2 id="结论">结论</h2><p>这个内容是我<code>Date:231023</code>做组会时的汇报，主要是结合了前段时间的工作展开介绍。写这篇Blog时，距离work DDL只有4天，所以算是Diffusion + NLP 的一篇收尾汇总啦。如果不出意外，此系列几乎不更新了。</p><p>算是第一篇内容Blog完结撒花 🎉 ？</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Acacia‘s 主页的诞生</title>
    <link href="/2023/10/25/HomePage-Building-Tutorial/"/>
    <url>/2023/10/25/HomePage-Building-Tutorial/</url>
    
    <content type="html"><![CDATA[<h1 id="快速搭建指南">快速搭建指南</h1><h2 id="前期准备工作">前期准备工作</h2><p>三个必要元素：使用git，下载node.js，挑选心仪的hexo主题。</p><p>hexo主题选择：<a href="https://hexo.io/index.html">hexo官网</a></p><p>网站搭建指南：<a href="https://hexo.io/zh-cn/docs/setup">hexo官方教程</a></p><h2 id="min快速搭建过程">50min快速搭建过程</h2><h4 id="主题选择">主题选择</h4><p>首先，参考官方指南操作（可以选择terminal的路径为Desktop）。指令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ <span class="hljs-built_in">cd</span> Desktop<br>$ hexo init &lt;folder&gt;<br>$ <span class="hljs-built_in">cd</span> &lt;folder&gt;<br>$ npm install<br></code></pre></td></tr></table></figure><p>然后，根据自己挑选的主题教程（下文参考来源），执行主题安装指令（以下为my theme）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ npm install --save hexo-theme-fluid<br></code></pre></td></tr></table></figure><p>然后在博客目录下创建 _config.fluid.yml，将主题的 _config.yml 内容复制进去。</p><p>修改 Hexo 博客目录中的 _config.yml：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">theme: fluid  <span class="hljs-comment"># 指定主题</span><br>language: zh-CN  <span class="hljs-comment"># 指定语言，会影响主题显示的语言，按需修改</span><br></code></pre></td></tr></table></figure><h3 id="页面相关操作一般在host4000">页面相关操作（一般在host4000）</h3><ol type="1"><li>预览页面</li></ol><p>根据如下指令结果打开静态页面：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><ol start="2" type="1"><li>生成静态文件</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><ol start="3" type="1"><li>Deploy/同步到github主页</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><ol start="4" type="1"><li>生成新Post</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><h3 id="github部署">Github部署</h3><p>首先，得给git设置代理，以下指令查看是否有代理。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ git config -l<br></code></pre></td></tr></table></figure><p>然后，在Github上创建新的仓库，仓库名需为'username.github.io'</p><p>再接着，需要绑定SSH。'user@email'处输入github登陆时使用的邮箱即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ ssh-keygen -t rsa -C user@email<br></code></pre></td></tr></table></figure><p>需要去找到ssh的key：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ <span class="hljs-built_in">cat</span> ~/.ssh/id_rsa.pub<br></code></pre></td></tr></table></figure><p>找到github setting，点击'ssh and GPG keys'，新建'ssh'，把上一步终端里面的内容复制进去。</p><p>在git bash输入指令查看是否生成成功。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ssh -T git@github.com<br></code></pre></td></tr></table></figure><p>最后，修改'_config.yml'最后一行的配置:</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-symbol">deploy:</span><br><span class="hljs-symbol">  type:</span> git<br><span class="hljs-symbol">  repository:</span> https:<span class="hljs-comment">//github.com/acaciasin/acaciasin.github.io.git</span><br><span class="hljs-symbol">  branch:</span> master<br></code></pre></td></tr></table></figure><p>且安装好'deploy-git'。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ npm install hexo-deployer-git --save<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>hello-world</title>
    <link href="/2023/10/25/hello-world/"/>
    <url>/2023/10/25/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="quick-start">Quick Start</h2><h3 id="create-a-new-post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="run-server">Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="generate-static-files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="deploy-to-remote-sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
